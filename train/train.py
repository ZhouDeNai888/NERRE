import os
import sys
# 1. ‡∏´‡∏≤ path ‡∏Ç‡∏≠‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÅ‡∏°‡πà (NERRE)
# (__file__ ‡∏Ñ‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô -> dirname ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 1 ‡πÑ‡∏î‡πâ 'train/' -> dirname ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà 2 ‡πÑ‡∏î‡πâ 'NERRE/')
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# 2. ‡πÄ‡∏û‡∏¥‡πà‡∏° path ‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
sys.path.append(parent_dir)

import torch
import torch.optim as optim
from torch.cuda.amp import GradScaler, autocast 
from transformers import AutoTokenizer
from torch.utils.data import DataLoader
from tqdm import tqdm

# --- Imports ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤ ---
from model.loss_fn.focal_loss import SigmoidFocalLoss 
from model.model import ZeroShotJointModel 
import train_config as config

# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Dataset ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ
from data.ZeroShotDataset import ZeroShotDataset, collate_fn


from data.hf_dataloader import generate_merged_dataset # import ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏µ‡πâ

# ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå train_data.json ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
if not os.path.exists(config.TRAIN_FILE):
    print("üì¢ Train file not found. Generating from Hugging Face datasets...")
    generate_merged_dataset(output_file=config.TRAIN_FILE)
else:
    print(f"‚úÖ Found existing train file: {config.TRAIN_FILE}")



# ==========================================
# Helper Function: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Label ‡∏ó‡∏µ‡πà‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô
# ==========================================
def prepare_batch_inputs(batch, tokenizer, device):
    """
    ‡πÅ‡∏õ‡∏•‡∏á List of Lists of Strings (Labels) ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Tensor ‡∏û‡∏£‡πâ‡∏≠‡∏° Padding
    ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ Model ‡πÑ‡∏î‡πâ
    """
    # 1. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Entity Labels
    # ent_labels_text ‡πÄ‡∏õ‡πá‡∏ô List[List[str]] ‡πÄ‡∏ä‡πà‡∏ô [['Per', 'Org'], ['Loc']]
    # ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Tensor ‡∏Ç‡∏ô‡∏≤‡∏î [Batch, Max_Num_Labels, Seq_Len]
    
    batch_ent_labels = batch['ent_labels_text']
    
    # ‡∏´‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Label ‡∏ó‡∏µ‡πà‡πÄ‡∏¢‡∏≠‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô Batch ‡∏ô‡∏µ‡πâ
    max_ent_labels = max(len(labels) for labels in batch_ent_labels)
    
    # Flatten ‡πÄ‡∏û‡∏∑‡πà‡∏≠ Tokenize ‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡πÄ‡∏£‡πá‡∏ß‡∏ß‡∏Å‡∏ß‡πà‡∏≤ loop)
    # ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏≥‡πÑ‡∏ß‡πâ‡∏ß‡πà‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞ sample ‡∏°‡∏µ‡∏Å‡∏µ‡πà label
    flat_ent_labels = []
    for labels in batch_ent_labels:
        flat_ent_labels.extend(labels)
        # ‡πÄ‡∏ï‡∏¥‡∏° Dummy label ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö Max (Padding logic)
        flat_ent_labels.extend(["O"] * (max_ent_labels - len(labels)))

    # Tokenize
    ent_inputs = tokenizer(flat_ent_labels, return_tensors="pt", padding=True, truncation=True).to(device)
    
    # Reshape ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô [Batch, Max_Labels, Seq_Len]
    # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Model ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Label ‡∏Ç‡∏≠‡∏á Sample ‡πÑ‡∏´‡∏ô
    b = len(batch_ent_labels)
    seq_len = ent_inputs['input_ids'].shape[1]
    
    ent_label_ids = ent_inputs['input_ids'].view(b, max_ent_labels, seq_len)
    ent_label_mask = ent_inputs['attention_mask'].view(b, max_ent_labels, seq_len)
    
    # 2. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Entity Targets (Padding)
    # ent_targets ‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏õ‡πá‡∏ô List of Tensors [Spans, Num_Labels]
    # ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á Pad ‡πÉ‡∏´‡πâ Num_Labels ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö max_ent_labels
    padded_ent_targets = []
    for i, t in enumerate(batch['ent_targets']):
        # t shape: [Num_Spans, Num_Actual_Labels]
        # ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£: [Num_Spans, Max_Ent_Labels]
        num_spans, num_actual = t.shape
        pad_size = max_ent_labels - num_actual
        
        if pad_size > 0:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ú‡πà‡∏ô Zero ‡∏°‡∏≤‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢
            padding = torch.zeros((num_spans, pad_size))
            t_padded = torch.cat([t, padding], dim=1)
        else:
            t_padded = t
        padded_ent_targets.append(t_padded.to(device))

    # --- ‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏Å‡∏±‡∏ö Relation (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ---
    # (‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ç‡∏≠‡∏•‡∏∞‡πÑ‡∏ß‡πâ ‡πÉ‡∏ä‡πâ Logic ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Entity)
    # ‡∏™‡∏°‡∏°‡∏ï‡∏¥ Relation Labels ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á Batch ‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢
    rel_inputs = tokenizer(batch['rel_labels_text'][0], return_tensors="pt", padding=True, truncation=True).to(device)
    rel_label_ids = rel_inputs['input_ids'].unsqueeze(0).repeat(b, 1, 1) # Repeat ‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤ Batch
    rel_label_mask = rel_inputs['attention_mask'].unsqueeze(0).repeat(b, 1, 1)
    
    # Pad Relation Targets (‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ Entity)
    padded_rel_targets = [t.to(device) for t in batch['rel_targets']]

    return (ent_label_ids, ent_label_mask), padded_ent_targets, \
           (rel_label_ids, rel_label_mask), padded_rel_targets

if __name__ == "__main__":
    # ==========================================
    # Main Training Script
    # ==========================================

    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Training on: {device}")

    # 1. Setup Data & Model
    tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Dataset ‡∏Ç‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á
    train_dataset = ZeroShotDataset(
        json_file=config.TRAIN_FILE, # ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô path json ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
        tokenizer=tokenizer,
        max_len=512,
        neg_sample_ratio=0.5
    )

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataLoader (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà collate_fn)
    train_dataloader = DataLoader(
        train_dataset, 
        batch_size=config.BATCH_SIZE, 
        shuffle=True, 
        collate_fn=collate_fn, # <--- ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å Class ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà import ‡∏°‡∏≤
        num_workers=4,         # ‡∏ä‡πà‡∏ß‡∏¢‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
        pin_memory=True
    )

    model = ZeroShotJointModel(config.MODEL_NAME).to(device)

    # 2. Setup Optimizer & Loss
    criterion = SigmoidFocalLoss(alpha=config.ALPHA, gamma=config.GAMMA, reduction='none') # ‡πÉ‡∏ä‡πâ 'none' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Padding ‡πÄ‡∏≠‡∏á
    optimizer = optim.AdamW(model.parameters(), lr=config.LR, weight_decay=config.WEIGHT_DECAY)
    scaler = torch.amp.GradScaler('cuda')

    # 3. Training Loop
    num_epochs = config.NUM_EPOCHS

    model.train()
    print(f"Start Training on {len(train_dataset)} samples...")

    for epoch in range(num_epochs):
        total_loss = 0
        
        # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏à‡∏≤‡∏Å DataLoader ‡∏Ç‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á
        loop = tqdm(train_dataloader, desc=f"Epoch {epoch+1}/{num_epochs}")
        for step, batch in enumerate(loop):
            
            # ‡∏¢‡πâ‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤ GPU
            text_ids = batch['text_ids'].to(device)
            text_mask = batch['text_mask'].to(device)
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Labels ‡πÅ‡∏•‡∏∞ Targets (‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Padding)
            (ent_lbl_ids, ent_lbl_mask), ent_targets, \
            (rel_lbl_ids, rel_lbl_mask), rel_targets = prepare_batch_inputs(batch, tokenizer, device)
            
            optimizer.zero_grad()
            
            with autocast():
                # Forward Pass
                # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: Model ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Label input ‡πÅ‡∏ö‡∏ö 3D [Batch, Num_Labels, Seq]
                # ‡∏ñ‡πâ‡∏≤ Model ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ Model ‡πÉ‡∏´‡πâ Flatten ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤ Encoder
                ent_logits, rel_logits = model(
                    text_ids, text_mask,
                    ent_lbl_ids, ent_lbl_mask,
                    rel_lbl_ids, rel_lbl_mask,
                    batch['spans'],
                    batch['pairs']
                )
                
                # --- Calculate Loss (Custom Loop) ---
                # ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å ent_logits ‡πÅ‡∏•‡∏∞ targets ‡πÄ‡∏õ‡πá‡∏ô List of Tensors (‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏ï‡∏≤‡∏° Spans)
                # ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Loss ‡∏ó‡∏µ‡∏•‡∏∞ Sample ‡πÉ‡∏ô Batch (‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Dynamic Data)
                
                loss_ent = 0
                loss_rel = 0
                valid_samples = 0
                
                # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏ó‡∏µ‡∏•‡∏∞ Sample ‡πÉ‡∏ô Batch
                for b in range(len(batch['spans'])):
                    # Entity Loss
                    # Logit: [Num_Spans, Max_Labels] -> ‡∏ï‡∏±‡∏î‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà Num_Labels ‡∏à‡∏£‡∏¥‡∏á
                    if len(batch['spans'][b]) > 0: # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ Span
                        num_real_labels = ent_targets[b].shape[1] # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Label ‡∏à‡∏£‡∏¥‡∏á (‡∏Å‡πà‡∏≠‡∏ô Pad)
                        
                        # ‡∏ï‡∏±‡∏î Logit ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô (Padding) ‡∏≠‡∏≠‡∏Å
                        curr_ent_logits = ent_logits[b, :len(batch['spans'][b]), :num_real_labels]
                        curr_ent_targets = ent_targets[b][:, :num_real_labels]
                        
                        l_ent = criterion(curr_ent_logits, curr_ent_targets)
                        loss_ent += l_ent.mean()
                        valid_samples += 1
                    
                    # Relation Loss (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
                    if rel_logits is not None and len(batch['pairs'][b]) > 0:
                        # (Logic ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)
                        l_rel = criterion(rel_logits[b, :len(batch['pairs'][b]), :], rel_targets[b])
                        loss_rel += l_rel.mean()

                # Average Loss
                if valid_samples > 0:
                    loss = (loss_ent + loss_rel) / valid_samples
                else:
                    loss = torch.tensor(0.0, requires_grad=True).to(device)

            # Backward
            scaler.scale(loss).backward()
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config.MAX_GRAD_NORM)
            scaler.step(optimizer)
            scaler.update()
            
            total_loss += loss.item()
            
            loop.set_postfix(loss=loss.item())

        avg_loss = total_loss / len(train_dataloader)
        print(f"--- Epoch {epoch+1} Finished. Avg Loss: {avg_loss:.4f} ---")
        
        # (Optional) Save Checkpoint here...

    print("Training Complete!")

    # --- Save Model ---
    os.makedirs(config.OUTPUT_DIR, exist_ok=True)
    torch.save(model.state_dict(), f"{config.OUTPUT_DIR}/pytorch_model.bin")
    tokenizer.save_pretrained(config.OUTPUT_DIR)
    # ... Save Config ...
    print(f"Model saved to {config.OUTPUT_DIR}")